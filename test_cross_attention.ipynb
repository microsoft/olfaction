{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading esm model...\n",
      "done loading esm model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdgllife\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m SMILESToBigraph\n\u001b[1;32m      7\u001b[0m smiles_to_g \u001b[39m=\u001b[39m SMILESToBigraph(add_self_loop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, node_featurizer\u001b[39m=\u001b[39mCanonicalAtomFeaturizer(),\n\u001b[1;32m      8\u001b[0m                                 edge_featurizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)    \n\u001b[0;32m---> 11\u001b[0m dataset \u001b[39m=\u001b[39m M2OR_Pairs(smiles_to_graph\u001b[39m=\u001b[39;49msmiles_to_g, \n\u001b[1;32m     12\u001b[0m         n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, cross_attention\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, load_full \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/olfaction/data/m2or.py:287\u001b[0m, in \u001b[0;36mM2OR_Pairs.__init__\u001b[0;34m(self, smiles_to_graph, node_featurizer, edge_featurizer, load, weighted_samples, cross_attention, load_full, log_every, cache_file_path, n_jobs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         sequences[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_len \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(sequences[i]))\n\u001b[1;32m    286\u001b[0m     \u001b[39m#print(sequences)\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     seq_embeddings \u001b[39m=\u001b[39m esm_embed(sequences, per_residue\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m## output shape: (batch_size, max_seq_len, embedding_dim)\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     seq_embeddings \u001b[39m=\u001b[39m esm_embed(sequences) \u001b[39m## output shape: (batch_size, embedding_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/olfaction/data/m2or.py:402\u001b[0m, in \u001b[0;36mesm_embed\u001b[0;34m(sequences, device, per_residue)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m per_residue:\n\u001b[1;32m    401\u001b[0m     \u001b[39mfor\u001b[39;00m i, tokens_len \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch_lens):\n\u001b[0;32m--> 402\u001b[0m         sequence_representations\u001b[39m.\u001b[39mappend(token_representations[i, \u001b[39m1\u001b[39;49m : \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    403\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[39mfor\u001b[39;00m i, tokens_len \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batch_lens):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data.m2or import M2OR_Pairs\n",
    "from dgllife.utils import SMILESToBigraph\n",
    "from dgllife.utils import CanonicalAtomFeaturizer\n",
    "from dgllife.utils import SMILESToBigraph\n",
    "\n",
    "\n",
    "smiles_to_g = SMILESToBigraph(add_self_loop=True, node_featurizer=CanonicalAtomFeaturizer(),\n",
    "                                edge_featurizer=None)    \n",
    "\n",
    "\n",
    "dataset = M2OR_Pairs(smiles_to_graph=smiles_to_g, \n",
    "        n_jobs=1, cross_attention=True, load_full = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 1280)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.seq_embeddings_dict[dataset.seq_id[3343]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graph_mask[3343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol_id</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>Responsive</th>\n",
       "      <th>_DataQuality</th>\n",
       "      <th>num_unique_value_screen</th>\n",
       "      <th>canonicalSMILES</th>\n",
       "      <th>mutated_Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m_0</td>\n",
       "      <td>s_29</td>\n",
       "      <td>1</td>\n",
       "      <td>ec50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CCC(CC1)C(=C)C</td>\n",
       "      <td>MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m_0</td>\n",
       "      <td>s_449</td>\n",
       "      <td>1</td>\n",
       "      <td>ec50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CCC(CC1)C(=C)C</td>\n",
       "      <td>MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m_0</td>\n",
       "      <td>s_539</td>\n",
       "      <td>0</td>\n",
       "      <td>ec50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CCC(CC1)C(=C)C</td>\n",
       "      <td>MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m_1</td>\n",
       "      <td>s_1</td>\n",
       "      <td>1</td>\n",
       "      <td>ec50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CCC(CC1=O)C(=C)C</td>\n",
       "      <td>MTEDNYSLTTEFILIGFSDHPDLKILLFLVLSTIYLVTMVGNLGLV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m_1</td>\n",
       "      <td>s_1051</td>\n",
       "      <td>0</td>\n",
       "      <td>ec50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC1=CCC(CC1=O)C(=C)C</td>\n",
       "      <td>MREENESSTTDFTLLGVTRQREQEYFFFILFLFIYPITVFGNMLII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46558</th>\n",
       "      <td>m_99</td>\n",
       "      <td>s_443</td>\n",
       "      <td>1</td>\n",
       "      <td>secondaryScreening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=CC=C2</td>\n",
       "      <td>MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46559</th>\n",
       "      <td>m_99</td>\n",
       "      <td>s_444</td>\n",
       "      <td>0</td>\n",
       "      <td>secondaryScreening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=CC=C2</td>\n",
       "      <td>MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46560</th>\n",
       "      <td>m_99</td>\n",
       "      <td>s_449</td>\n",
       "      <td>0</td>\n",
       "      <td>secondaryScreening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=CC=C2</td>\n",
       "      <td>MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46561</th>\n",
       "      <td>m_99</td>\n",
       "      <td>s_450</td>\n",
       "      <td>0</td>\n",
       "      <td>secondaryScreening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=CC=C2</td>\n",
       "      <td>MDEANHSVVSEFVFLGLSDSRKIQLLLFLFFSVFYVSSLMGNLLIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46562</th>\n",
       "      <td>m_99</td>\n",
       "      <td>s_51</td>\n",
       "      <td>0</td>\n",
       "      <td>secondaryScreening</td>\n",
       "      <td>4.0</td>\n",
       "      <td>C1=CC=C(C=C1)OC2=CC=CC=C2</td>\n",
       "      <td>MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46563 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mol_id  ...                                   mutated_Sequence\n",
       "0        m_0  ...  MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...\n",
       "1        m_0  ...  MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...\n",
       "2        m_0  ...  MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...\n",
       "3        m_1  ...  MTEDNYSLTTEFILIGFSDHPDLKILLFLVLSTIYLVTMVGNLGLV...\n",
       "4        m_1  ...  MREENESSTTDFTLLGVTRQREQEYFFFILFLFIYPITVFGNMLII...\n",
       "...      ...  ...                                                ...\n",
       "46558   m_99  ...  MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...\n",
       "46559   m_99  ...  MRENNQSSTLEFILLGVTGQQEQEDFFYILFLFIYPITLIGNLLIV...\n",
       "46560   m_99  ...  MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...\n",
       "46561   m_99  ...  MDEANHSVVSEFVFLGLSDSRKIQLLLFLFFSVFYVSSLMGNLLIV...\n",
       "46562   m_99  ...  MDQSNYSSLHGFILLGFSNHPKMEMILSGVVAIFYLITLVGNTAII...\n",
       "\n",
       "[46563 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/datasets/M2OR_original_mol_OR_pairs.csv'\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_path, sep = ';')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MQPTATMATAATTTTTTTATVALTTSWDNATGRPTAEPDPILDNYVLLVVVMSLFVGGTLVVLSGVLLLCKRCWDVHQRLNRAMEEAEKTTTTYLDNGTHPAQDPDFRGEDPECQDAETERFLSTSSTGRRVSFNEAALFEQSRKTQDKGRRYTLTEGDFHHLKNARLTHLHLPPLKIVTIHECDSGEASSATTPHPATSPKATLAIFQPPGKALTGRSVGPSSALPGDPYNSAAGATDFAEISPSASSDSGEGTSLDAGTRSTKAGGPGAAAGPGEAGPGSGAGTVLQFLTRLRRHASLDGASPYFKVKKWKLEPSQRAASLDTRGSPKRHHFQRQRAASESTEQEEGDAPQEDFIQYIARAGDAVAFPHPRPFLASPPPALGRLEAAEAAGGASPDSPPERGAGSAGPEQQQPPLEPDAERDAGPEQAQTSYRDLWSLRASLELHAAASDHSSSGNDRDSVRSGDSSGSGSGGAAPAFPPPSPPAPRPKDGEARRLLQMDSGYASIEGRGAGDDTEPPAAPARPRSPRAWPRRPRRDYSIDEKTDALFHEFLRHDPHFDDTPAAARHRARAHPHARKQWQRGRQHSDPGARAAPALAGTPAPPAGAARPARAPLRRGDSVDGPPDGRTLGGAGDDPAIPVIEEEPGGGGCPGSGLCVLPSGSVLDKLAAGLDERLFPPRLAEPVVATPALVAAAPTSPDHSPA'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['mutated_Sequence'].tolist(), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('MQPTATMATAATTTTTTTATVALTTSWDNATGRPTAEPDPILDNYVLLVVVMSLFVGGTLVVLSGVLLLCKRCWDVHQRLNRAMEEAEKTTTTYLDNGTHPAQDPDFRGEDPECQDAETERFLSTSSTGRRVSFNEAALFEQSRKTQDKGRRYTLTEGDFHHLKNARLTHLHLPPLKIVTIHECDSGEASSATTPHPATSPKATLAIFQPPGKALTGRSVGPSSALPGDPYNSAAGATDFAEISPSASSDSGEGTSLDAGTRSTKAGGPGAAAGPGEAGPGSGAGTVLQFLTRLRRHASLDGASPYFKVKKWKLEPSQRAASLDTRGSPKRHHFQRQRAASESTEQEEGDAPQEDFIQYIARAGDAVAFPHPRPFLASPPPALGRLEAAEAAGGASPDSPPERGAGSAGPEQQQPPLEPDAERDAGPEQAQTSYRDLWSLRASLELHAAASDHSSSGNDRDSVRSGDSSGSGSGGAAPAFPPPSPPAPRPKDGEARRLLQMDSGYASIEGRGAGDDTEPPAAPARPRSPRAWPRRPRRDYSIDEKTDALFHEFLRHDPHFDDTPAAARHRARAHPHARKQWQRGRQHSDPGARAAPALAGTPAPPAGAARPARAPLRRGDSVDGPPDGRTLGGAGDDPAIPVIEEEPGGGGCPGSGLCVLPSGSVLDKLAAGLDERLFPPRLAEPVVATPALVAAAPTSPDHSPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "esm_model = None\n",
    "esm_alphabet = None\n",
    "def setup_esm(device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')):\n",
    "    import esm\n",
    "    # Load ESM-2 model\n",
    "    global esm_model\n",
    "    global esm_alphabet\n",
    "    if esm_model is None:\n",
    "        print('loading esm model...')\n",
    "        esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D() ######################################\n",
    "        esm_model.eval()  # disables dropout for deterministic results\n",
    "        esm_model.to(device)\n",
    "        print('done loading esm model')\n",
    "    return esm_model, esm_alphabet\n",
    "\n",
    "def esm_embed(sequences, device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'), per_residue = False):\n",
    "    # get the embeddings for a list of sequences. Code is copied from ESM github readme\n",
    "    assert isinstance(sequences, list)\n",
    "    esm_model, esm_alphabet = setup_esm()\n",
    "    batch_converter = esm_alphabet.get_batch_converter()\n",
    "    \n",
    "    def divide_chunks(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i + n]\n",
    "\n",
    "    sequence_representations = []\n",
    "    sequence_chunks = list(divide_chunks(sequences, 5))\n",
    "    for sequence_chunk in sequence_chunks:\n",
    "        data = []\n",
    "        for i, sequence in enumerate(sequence_chunk):\n",
    "            assert ' ' not in sequence\n",
    "            if len(sequence) > 1600:\n",
    "                print('trimming sequence to 1600 amino acids max')\n",
    "                sequence = sequence[0:1600]\n",
    "            data.append(('protein' + str(i), sequence))\n",
    "    \n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "        batch_lens = (batch_tokens != esm_alphabet.padding_idx).sum(1)\n",
    "\n",
    "        # Extract per-residue representations (on CPU)\n",
    "        with torch.inference_mode():\n",
    "            results = esm_model(batch_tokens.to(device), repr_layers=[33], return_contacts=False)\n",
    "        token_representations = results[\"representations\"][33]\n",
    "        #print(token_representations.shape)\n",
    "\n",
    "        # Generate per-sequence representations via averaging\n",
    "        # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "        #print (batch_lens)\n",
    "        if per_residue:\n",
    "            for i, tokens_len in enumerate(batch_lens):\n",
    "                sequence_representations.append(token_representations[i, 1 : -1].detach().cpu().numpy())\n",
    "        else:\n",
    "            for i, tokens_len in enumerate(batch_lens):\n",
    "                sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0).detach().cpu().numpy())\n",
    "    return sequence_representations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 1280)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esm_embed(['AAA<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'], per_residue=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    \"\"\"Cross-Attention Block of ligand-protein model, that takes in two 2d tensors for the molecular and protein embeddings, collapses them to the same\n",
    "    dimension, and performs a cross-attention between them. \n",
    "    \n",
    "    Args:\n",
    "        D1 (int): dimension of input protein tensor\n",
    "        D2 (int): dimension of input mol tensor (usually smaller)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, D1, D2):\n",
    "        super(CrossAttention, self).__init__()\n",
    "\n",
    "        # Define the trainable weight matrices for query, key, and value transformations\n",
    "        self.query_transform_tensor1 = nn.Linear(D1, D2)\n",
    "        self.key_transform_tensor1 = nn.Linear(D1, D2)\n",
    "        self.value_transform_tensor1 = nn.Linear(D1, D2)\n",
    "\n",
    "        self.query_transform_tensor2 = nn.Linear(D2, D2)\n",
    "        self.key_transform_tensor2 = nn.Linear(D2, D2)\n",
    "        self.value_transform_tensor2 = nn.Linear(D2, D2)\n",
    "\n",
    "        # 1D Convolutional layer for aggregation\n",
    "        self.linear1 = nn.Linear(D2, 1)\n",
    "        self.linear2 = nn.Linear(D2, 1)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k).float())\n",
    "        #attention_weights = torch.softmax(scores, dim=-1) ## try relu here, then softmax at the end w/ the MLP prediction head\n",
    "        attention_weights = torch.relu(scores)\n",
    "        attended_values = torch.matmul(attention_weights, value)\n",
    "        return attended_values\n",
    "\n",
    "    def forward(self, tensor1, tensor2):\n",
    "        # Compute query, key, and value representations for both tensors\n",
    "        query_tensor1 = self.query_transform_tensor1(tensor1)\n",
    "        key_tensor1 = self.key_transform_tensor1(tensor1)\n",
    "        value_tensor1 = self.value_transform_tensor1(tensor1)\n",
    "\n",
    "        query_tensor2 = self.query_transform_tensor2(tensor2)\n",
    "        key_tensor2 = self.key_transform_tensor2(tensor2)\n",
    "        value_tensor2 = self.value_transform_tensor2(tensor2)\n",
    "\n",
    "        # Compute cross-attention between tensor1 and tensor2\n",
    "        attended_values_tensor1 = self.scaled_dot_product_attention(query_tensor1, key_tensor2, value_tensor2) ## outputs (batch_size, R, D2)\n",
    "        attended_values_tensor2 = self.scaled_dot_product_attention(query_tensor2, key_tensor1, value_tensor1) ## outputs (batch_size, A, D2)\n",
    "        print(attended_values_tensor1.shape)\n",
    "        print(attended_values_tensor2.shape)\n",
    "        #attended_values_tensor2 = self.scaled_dot_product_attention(query_tensor2, key_tensor1, value_tensor1)\n",
    "\n",
    "        # Apply Linear for aggregation\n",
    "        fixed_size_tensor1 = self.linear1(attended_values_tensor1).squeeze(-1) ## outputs (batch_size, R)\n",
    "        fixed_size_tensor2 = self.linear2(attended_values_tensor2).squeeze(-1) ## outputs (batch_size, R)\n",
    "        print(fixed_size_tensor1.shape)\n",
    "        print(fixed_size_tensor2.shape)\n",
    "        return fixed_size_tensor1, fixed_size_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32])\n",
      "torch.Size([7, 32])\n",
      "torch.Size([5])\n",
      "torch.Size([7])\n",
      "Output1 shape: torch.Size([5])\n",
      "Output2 shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "R, D1 = 5, 64\n",
    "A, D2 = 7, 32\n",
    "\n",
    "tensor1 = torch.randn(R, D1)\n",
    "tensor2 = torch.randn(A, D2)\n",
    "\n",
    "cross_attention = CrossAttention(D1, D2)\n",
    "output1, output2 = cross_attention(tensor1, tensor2)\n",
    "\n",
    "print(\"Output1 shape:\", output1.shape)  # Output1 shape: torch.Size([1, 32])\n",
    "print(\"Output2 shape:\", output2.shape)  # Output2 shape: torch.Size([1, 32])\n",
    "#In this example, output1 and output2 are the fixed-size vector representations of the two tensors after cross-attention, with shape (1, D2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgllife.utils import ScaffoldSplitter, RandomSplitter\n",
    "\n",
    "train_set, val_set, test_set = RandomSplitter.train_val_test_split(\n",
    "    dataset, frac_train=0.8, frac_val=0.1, frac_test=0.1, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl \n",
    "import torch\n",
    "def collate_molgraphs(data):\n",
    "    \"\"\"Batching a list of datapoints for dataloader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list of 3-tuples or 4-tuples.\n",
    "        Each tuple is for a single datapoint, consisting of\n",
    "        a SMILES, a DGLGraph, all-task labels and optionally a binary\n",
    "        mask indicating the existence of labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    smiles : list\n",
    "        List of smiles\n",
    "    bg : DGLGraph\n",
    "        The batched DGLGraph.\n",
    "    labels : Tensor of dtype float32 and shape (B, T)\n",
    "        Batched datapoint labels. B is len(data) and\n",
    "        T is the number of total tasks.\n",
    "    masks : Tensor of dtype float32 and shape (B, T)\n",
    "        Batched datapoint binary mask, indicating the\n",
    "        existence of labels.\n",
    "    \"\"\"\n",
    "    ids, seq_ids, sequences_dict, seq_embeddings = None, None, None, None\n",
    "    if len(data[0]) == 3:\n",
    "        smiles, graphs, labels = map(list, zip(*data))\n",
    "    elif len(data[0]) == 9:\n",
    "        smiles, graphs, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights = map(list, zip(*data))\n",
    "    elif len(data[0]) == 11:\n",
    "        smiles, graphs, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights, seq_mask, node_mask = map(list, zip(*data))\n",
    "    else:\n",
    "        smiles, graphs, labels, masks = map(list, zip(*data))\n",
    "\n",
    "    bg = dgl.batch(graphs)\n",
    "    bg.set_n_initializer(dgl.init.zero_initializer)\n",
    "    bg.set_e_initializer(dgl.init.zero_initializer)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "\n",
    "    if len(data[0]) == 3:\n",
    "        masks = torch.ones(labels.shape)\n",
    "    else:\n",
    "        masks = torch.stack(masks, dim=0)\n",
    "    \n",
    "    if len(data[0]) == 9:\n",
    "        return smiles, bg, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights\n",
    "    elif len(data[0]) == 11:\n",
    "        return smiles, bg, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights, seq_mask, node_mask\n",
    "    return smiles, bg, labels, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True,\n",
    "                            collate_fn=collate_molgraphs, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n",
      "torch.Size([64, 705, 1280])\n",
      "torch.Size([64, 705]) torch.Size([64, 22])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, batch_data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      3\u001b[0m     smiles, bg, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights, seq_mask, node_mask \u001b[39m=\u001b[39m batch_data\n\u001b[0;32m----> 5\u001b[0m     seq_emb_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdstack(seq_embeddings)\n\u001b[1;32m      6\u001b[0m     seq_embeddings_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(np\u001b[39m.\u001b[39mrollaxis(seq_emb_arr, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(seq_embeddings_tensor\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/anaconda/envs/dgllife/lib/python3.8/site-packages/numpy/lib/shape_base.py:723\u001b[0m, in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    722\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 723\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "for batch_id, batch_data in enumerate(train_loader):\n",
    "    smiles, bg, labels, masks, ids, seq_ids, sequences_dict, seq_embeddings, sample_weights, seq_mask, node_mask = batch_data\n",
    "    \n",
    "    seq_emb_arr = np.dstack(seq_embeddings)\n",
    "    seq_embeddings_tensor = torch.FloatTensor(np.rollaxis(seq_emb_arr, -1)).cuda()\n",
    "    print(seq_embeddings_tensor.shape)\n",
    "    #print(seq_embeddings.shape)\n",
    "    seq_mask = np.vstack(seq_mask)\n",
    "    seq_mask = torch.FloatTensor(seq_mask).cuda()\n",
    "    \n",
    "    node_mask = np.vstack(node_mask)\n",
    "    node_mask = torch.FloatTensor(node_mask).cuda()\n",
    "\n",
    "    print(seq_mask.shape, node_mask.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = len(max(df['mutated_Sequence'].tolist(), key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a 2d tensor of shape (len(df), max_seq_len), and for each row i, fill it with an array of len(sequences[i]) 1's and the rest are 0's. \n",
    "## This will be used as the attention mask for the cross attention layer.\n",
    "sequences = df['mutated_Sequence'].tolist()\n",
    "seq_mask = torch.zeros((len(df), max_seq_len))\n",
    "for i in range(len(df)):\n",
    "    seq_mask[i, :len(sequences[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46563, 705])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs[0].num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node_len = max([graph.num_nodes() for graph in dataset.graphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([705])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask[44384].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_mask = torch.zeros((len(dataset.graphs), max_node_len))\n",
    "for idx in range(len(dataset)):\n",
    "    graph_mask[idx, :dataset.graphs[idx].num_nodes()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_mask[4444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46563"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([433, 22])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_mask[1:434].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CrossAttention(nn.Module):\n",
    "    \n",
    "    \"\"\"Cross-Attention Block of ligand-protein model, that takes in two 2d tensors for the molecular and protein embeddings, collapses them to the same\n",
    "    dimension, and performs a cross-attention between them. \n",
    "    \n",
    "    Args:\n",
    "        D1 (int): dimension of input protein tensor\n",
    "        D2 (int): dimension of input mol tensor (usually smaller)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, D1, D2):\n",
    "        super(CrossAttention, self).__init__()\n",
    "\n",
    "        # Define the trainable weight matrices for query, key, and value transformations\n",
    "        self.query_transform_tensor1 = nn.Linear(D1, D2)\n",
    "        self.key_transform_tensor1 = nn.Linear(D1, D2)\n",
    "        self.value_transform_tensor1 = nn.Linear(D1, D2)\n",
    "\n",
    "        self.query_transform_tensor2 = nn.Linear(D2, D2)\n",
    "        self.key_transform_tensor2 = nn.Linear(D2, D2)\n",
    "        self.value_transform_tensor2 = nn.Linear(D2, D2)\n",
    "\n",
    "        # Linear layer for aggregation\n",
    "        self.linear1 = nn.Linear(D2, 1)\n",
    "        self.linear2 = nn.Linear(D2, 1)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k).float())\n",
    "        #attention_weights = torch.softmax(scores, dim=-1) ## try relu here, then softmax at the end w/ the MLP prediction head\n",
    "        attention_weights = torch.relu(scores)\n",
    "        attended_values = torch.matmul(attention_weights, value)\n",
    "        return attended_values\n",
    "\n",
    "    def forward(self, tensor1, tensor2, seq_mask = None, node_mask = None):\n",
    "        # Compute query, key, and value representations for both tensors\n",
    "        tensor1 = tensor1 * seq_mask[:, :, np.newaxis]\n",
    "        query_tensor1 = self.query_transform_tensor1(tensor1)\n",
    "        key_tensor1 = self.key_transform_tensor1(tensor1)\n",
    "        value_tensor1 = self.value_transform_tensor1(tensor1)\n",
    "\n",
    "        query_tensor2 = self.query_transform_tensor2(tensor2)\n",
    "        key_tensor2 = self.key_transform_tensor2(tensor2)\n",
    "        value_tensor2 = self.value_transform_tensor2(tensor2)\n",
    "\n",
    "        # Compute cross-attention between tensor1 and tensor2\n",
    "        attended_values_tensor1 = self.scaled_dot_product_attention(query_tensor1, key_tensor2, value_tensor2) ## outputs (batch_size, R, D2)\n",
    "        attended_values_tensor2 = self.scaled_dot_product_attention(query_tensor2, key_tensor1, value_tensor1) ## outputs (batch_size, A, D2)\n",
    "        print(attended_values_tensor1.shape)\n",
    "        print(attended_values_tensor2.shape)\n",
    "        #attended_values_tensor2 = self.scaled_dot_product_attention(query_tensor2, key_tensor1, value_tensor1)\n",
    "\n",
    "        # Apply Linear for aggregation\n",
    "        fixed_size_tensor1 = self.linear1(attended_values_tensor1).squeeze(-1) ## outputs (batch_size, R)\n",
    "        fixed_size_tensor2 = self.linear2(attended_values_tensor2).squeeze(-1) ## outputs (batch_size, R)\n",
    "        \n",
    "        print(fixed_size_tensor1.shape, fixed_size_tensor2.shape)\n",
    "        \n",
    "        return fixed_size_tensor1, fixed_size_tensor2    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, D1 = 705, 1280\n",
    "A, D2 = 22, 256\n",
    "\n",
    "tensor1 = torch.randn(2, R, D1)\n",
    "tensor2 = torch.randn(2, A, D2)\n",
    "\n",
    "mask1 = torch.ones((2,R))\n",
    "mask1[400:] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 705, 1280])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tensor1 * mask1[:, :, np.newaxis]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 705, 256])\n",
      "torch.Size([2, 22, 256])\n",
      "torch.Size([2, 705]) torch.Size([2, 22])\n",
      "Output1 shape: torch.Size([2, 705])\n",
      "Output2 shape: torch.Size([2, 22])\n"
     ]
    }
   ],
   "source": [
    "R, D1 = 705, 1280\n",
    "A, D2 = 22, 256\n",
    "\n",
    "tensor1 = torch.randn(2, R, D1)\n",
    "tensor2 = torch.randn(2, A, D2)\n",
    "\n",
    "cross_attention = CrossAttention(D1, D2)\n",
    "\n",
    "seq_mask = torch.ones((2, R))\n",
    "\n",
    "output1, output2 = cross_attention(tensor1, tensor2, seq_mask)\n",
    "\n",
    "print(\"Output1 shape:\", output1.shape)  # Output1 shape: torch.Size([1, 32])\n",
    "print(\"Output2 shape:\", output2.shape)  # Output2 shape: torch.Size([1, 32])\n",
    "#In this example, output1 and output2 are the fixed-size vector representations of the two tensors after cross-attention, with shape (1, D2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9199,  2.0333, -0.4808, -0.6681, -1.9653,  3.0707,  0.5324, -2.7096,\n",
       "         -1.8324, -1.0475,  0.1393, -1.8973,  0.4469, -1.5381, -1.1548, -0.2025,\n",
       "         -0.3511,  0.0686, -2.7342, -0.5233, -2.0736, -4.1108],\n",
       "        [-4.1297, -2.6616,  2.1760, -1.1716,  0.5314,  1.4921,  0.1804, -1.3151,\n",
       "          2.7273, -0.6498,  6.7817, -3.5639, -0.0154,  2.2489, -3.4568, -0.6560,\n",
       "         -1.0690, -4.2612, -3.5600, -1.5677,  0.5680,  0.3355]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_mask = torch.zeros((2, 22))\n",
    "output2[node_mask == 0] = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf]],\n",
       "       grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\x89c\\x90n\\xda\\xad\\xf2\\x8f\\xec\\xc9~\\xd0\\x1dJ\\xff\\xb7\\xabN \\xb33qZ\\xc2AQ\\x16\\x84I\\x14\\x83\\xde\\x8a\\xdb\\xff\\xc8\\xb2\\x17#|O\\xb5\\xb1\\xcb\\x18\\x90\\x8a\\xc5\\x8f\\x85\\xd0\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0']\n",
      "Bad pipe message: %s [b'.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04']\n",
      "Bad pipe message: %s [b'\\x03\\x06', b'\\x07\\x08']\n",
      "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
      "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\xaaE\\x06\\xb2+\\xd1\\xad\\xff^\\xc7! \\xf8+\\xf4\\xdf\\x84\\x1d\\xf7\\xb5\\xa6\\x14']\n",
      "Bad pipe message: %s [b'P\\xcb1\\xff\\xd3K_z\\x17O\\x92\\xc7\\xc8\\xa9\\x1a\\xae\\xa0{ ']\n",
      "Bad pipe message: %s [b'\\xc8N\\xcf\\x84Dw\\xc99\\xe1\\xdf\\xeaM\\xe3\\xf5\\xfb?m>\\xa8/k[\\x08\\x03\\xb1;X\\xd6\\xedd\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 g\\xdc=\\xd9\\x12\\x7fW\\x1e|\\xa7\\xf1F\\x7f']\n",
      "Bad pipe message: %s [b\"T\\x8c\\xbb4\\xbc\\x1e;\\xc4\\x86M\\x9d\\xc6\\xda\\xa9\\x96<\\x98\\x88\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x00\", b'\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c']\n",
      "Bad pipe message: %s [b\"\\xe1\\t\\x8d\\xae\\xb6&,b(\\xf0\\xb8 X\\x17\\xb5,\\xd8\\x9c\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0\"]\n",
      "Bad pipe message: %s [b'.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04']\n",
      "Bad pipe message: %s [b'\\x03\\x06', b'\\x07\\x08']\n",
      "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
      "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xd35%\\x8f~Y\\x96\\x975\\xc6\\xc2H[\\x91D\\x98\\xa1$\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0']\n",
      "Bad pipe message: %s [b'\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00']\n",
      "Bad pipe message: %s [b'\\x10\\xe5\\xa0{\\xeb\\xd3#\\xb4dzU\\xef\\x1d\\x80-\\xd6\\x1a1\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00']\n",
      "Bad pipe message: %s [b'\\x06\\x00\\x17\\x00\\x03\\xc0\\x10']\n",
      "Bad pipe message: %s [b'r\\x92H\\xc0\\x84\\x14', b'\\xc0h\\xa1*Einh\\xa4d\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff']\n",
      "Bad pipe message: %s [b\"\\x13\\xcdXn\\xbe[\\n\\x07W\\x1d\\xb1~\\x93\\\\\\xf1\\x16\\x9e4\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00\", b'\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02\\x01\\x02\\x02\\x02\\x03']\n",
      "Bad pipe message: %s [b\"\\xe9\\x95Zl\\xe0\\x93\\x15\\xcb/\\xc0\\xad\\x0c0\\x9c\\xf6\\xacE\\xc1\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\", b'\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08']\n"
     ]
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 74])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs[3763].ndata['h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_att = CrossAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 74])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs[0].ndata['h'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7f5f7ead3ac0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs[0].local_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "bg = dgl.batch(dataset.graphs[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "bg.ndata['logits'] = torch.randn(349, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = dgl.unbatch(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=349, num_edges=1047,\n",
       "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32), 'logits': Scheme(shape=(256,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_batch_feats = torch.zeros((32, 22, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0].ndata['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graphs)):\n",
    "    empty_batch_feats[i][:graphs[i].num_nodes()] = graphs[i].ndata['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_batch_feats.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats_lst = [g.ndata['logits'] for g in graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mcat([node_feats_lst], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "torch.cat([node_feats_lst], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 10 and the array at index 3 has size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m seq_emb_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdstack(node_feats_lst)\n\u001b[1;32m      4\u001b[0m seq_embeddings_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(np\u001b[39m.\u001b[39mrollaxis(seq_emb_arr, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/anaconda/envs/dgllife/lib/python3.8/site-packages/numpy/lib/shape_base.py:723\u001b[0m, in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    722\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[0;32m--> 723\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 10 and the array at index 3 has size 11"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "seq_emb_arr = np.dstack(node_feats_lst)\n",
    "seq_embeddings_tensor = torch.FloatTensor(np.rollaxis(seq_emb_arr, -1)).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-initialize ESM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading esm model...\n",
      "done loading esm model\n"
     ]
    }
   ],
   "source": [
    "import esm\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('loading esm model...')\n",
    "esm_model, esm_alphabet = esm.pretrained.esm2_t33_650M_UR50D() ######################################\n",
    "esm_model.eval()  # disables dropout for deterministic results\n",
    "esm_model.to(device)\n",
    "print('done loading esm model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1746,  0.0135,  0.1160,  ...,  0.0136, -0.0836,  0.0016],\n",
       "        [ 0.0905, -0.0453,  0.0685,  ...,  0.0663,  0.0138,  0.0146],\n",
       "        [-0.0400,  0.0616,  0.0203,  ...,  0.0631, -0.0950,  0.0014],\n",
       "        ...,\n",
       "        [ 0.0133, -0.0549, -0.0352,  ...,  0.0392, -0.0723, -0.1175],\n",
       "        [-0.0209,  0.0558,  0.0616,  ..., -0.2120,  0.0193, -0.0345],\n",
       "        [ 0.0592,  0.0552, -0.0665,  ..., -0.0968, -0.0383, -0.0413]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esm_model.layers[1].self_attn.k_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def reinitialize_weights(model):\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'embed' in name:  # Re-initialize embeddings\n",
    "            if len(param.size()) > 1:\n",
    "                init.normal_(param.data, mean=0.0, std=0.02)\n",
    "        elif 'weight' in name:  # Re-initialize weights of linear layers\n",
    "            if len(param.size()) > 1:\n",
    "                init.xavier_normal_(param.data)\n",
    "        elif 'bias' in name:  # Re-initialize biases of linear layers\n",
    "            init.constant_(param.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinitialize_weights(esm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0099,  0.0066, -0.0063,  ...,  0.0732,  0.0589,  0.0390],\n",
       "        [-0.0147,  0.0116, -0.0337,  ...,  0.0113,  0.0162, -0.0036],\n",
       "        [-0.0050, -0.0034, -0.0055,  ...,  0.0067, -0.0099,  0.0064],\n",
       "        ...,\n",
       "        [ 0.0121,  0.0537,  0.0081,  ..., -0.0064,  0.0105,  0.0033],\n",
       "        [ 0.0232,  0.0046, -0.0282,  ...,  0.0191,  0.0042,  0.0178],\n",
       "        [-0.0004,  0.0194,  0.0183,  ..., -0.0050, -0.0182, -0.0219]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esm_model.layers[1].self_attn.k_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgllife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
